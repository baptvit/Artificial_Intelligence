{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hand tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "  * Use the `LinearRegressor` class in TensorFlow to predict median housing price, at the granularity of city blocks, based on one input feature\n",
    "  * Evaluate the accuracy of a model's predictions using Root Mean Squared Error (RMSE)\n",
    "  * Improve the accuracy of a model by hand-tuning its hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is based on 1990 census data from California. This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively.  Using only one input feature -- the number of rooms -- predict house value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Set Up\n",
    "In this first cell, we'll load the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Next, we'll load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Examine the data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it.\n",
    "\n",
    "We'll print out a quick summary of a few useful statistics on each column.\n",
    "\n",
    "This will include things like mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0     -114.3      34.2                15.0       5612.0          1283.0   \n",
       "1     -114.5      34.4                19.0       7650.0          1901.0   \n",
       "2     -114.6      33.7                17.0        720.0           174.0   \n",
       "3     -114.6      33.6                14.0       1501.0           337.0   \n",
       "4     -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0            1.5             66900.0  \n",
       "1      1129.0       463.0            1.8             80100.0  \n",
       "2       333.0       117.0            1.7             85700.0  \n",
       "3       515.0       226.0            3.2             73400.0  \n",
       "4       624.0       262.0            1.9             65500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9            207300.9  \n",
       "std        1147.9       384.5            1.9            115983.8  \n",
       "min           3.0         1.0            0.5             14999.0  \n",
       "25%         790.0       282.0            2.6            119400.0  \n",
       "50%        1167.0       409.0            3.5            180400.0  \n",
       "75%        1721.0       605.2            4.8            265000.0  \n",
       "max       35682.0      6082.0           15.0            500001.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll be trying to predict median_house_value. It will be our label (sometimes also called a target). Can we use total_rooms as our input feature?  What's going on with the values for that feature?\n",
    "\n",
    "This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively.  Let's create a different, more appropriate feature.  Because we are predicing the price of a single house, we should try to make all our features correspond to a single house as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>num_rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>141.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  num_rooms  \n",
       "count     17000.0     17000.0        17000.0             17000.0    17000.0  \n",
       "mean       1429.6       501.2            3.9            207300.9        5.4  \n",
       "std        1147.9       384.5            1.9            115983.8        2.5  \n",
       "min           3.0         1.0            0.5             14999.0        0.8  \n",
       "25%         790.0       282.0            2.6            119400.0        4.4  \n",
       "50%        1167.0       409.0            3.5            180400.0        5.2  \n",
       "75%        1721.0       605.2            4.8            265000.0        6.1  \n",
       "max       35682.0      6082.0           15.0            500001.0      141.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_rooms'] = df['total_rooms'] / df['households']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and eval\n",
    "np.random.seed(seed=1) #makes split reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Build the first model\n",
    "\n",
    "In this exercise, we'll be trying to predict `median_house_value`. It will be our label (sometimes also called a target). We'll use `num_rooms` as our input feature.\n",
    "\n",
    "To train our model, we'll use the [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) estimator. The Estimator takes care of a lot of the plumbing, and exposes a convenient way to interact with data, training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0809 02:13:21.599086 139891397056256 estimator.py:1790] Using default config.\n",
      "I0809 02:13:21.601280 139891397056256 estimator.py:209] Using config: {'_experimental_max_worker_delay_secs': None, '_model_dir': './housing_trained', '_task_type': 'worker', '_evaluation_master': '', '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a949ce8d0>, '_task_id': 0, '_save_checkpoints_steps': None, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_train_distribute': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_max': 5, '_service': None}\n",
      "I0809 02:13:21.603398 139891397056256 estimator.py:209] Using config: {'_experimental_max_worker_delay_secs': None, '_model_dir': './housing_trained', '_task_type': 'worker', '_evaluation_master': '', '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a949ced30>, '_task_id': 0, '_save_checkpoints_steps': None, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_train_distribute': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_max': 5, '_service': None}\n",
      "I0809 02:13:21.612798 139891397056256 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0809 02:13:21.614246 139891397056256 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0809 02:13:21.615283 139891397056256 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0809 02:13:21.647173 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:13:21.648627 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:13:21.878628 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:13:21.879971 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:13:21.881302 139891397056256 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0809 02:13:22.009582 139891397056256 monitored_session.py:240] Graph was finalized.\n",
      "I0809 02:13:22.067890 139891397056256 session_manager.py:500] Running local_init_op.\n",
      "I0809 02:13:22.075641 139891397056256 session_manager.py:502] Done running local_init_op.\n",
      "I0809 02:13:22.314100 139891397056256 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./housing_trained/model.ckpt.\n",
      "I0809 02:13:22.538239 139891397056256 basic_session_run_hooks.py:262] loss = 7078117600000.0, step = 1\n",
      "I0809 02:13:22.870548 139891397056256 basic_session_run_hooks.py:606] Saving checkpoints for 100 into ./housing_trained/model.ckpt.\n",
      "I0809 02:13:22.940565 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:13:22.943929 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:13:23.442774 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:13:23.466042 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:13:23.489878 139891397056256 evaluation.py:255] Starting evaluation at 2019-08-09T02:13:23Z\n",
      "I0809 02:13:23.590459 139891397056256 monitored_session.py:240] Graph was finalized.\n",
      "I0809 02:13:23.595390 139891397056256 saver.py:1280] Restoring parameters from ./housing_trained/model.ckpt-100\n",
      "I0809 02:13:23.645242 139891397056256 session_manager.py:500] Running local_init_op.\n",
      "I0809 02:13:23.680663 139891397056256 session_manager.py:502] Done running local_init_op.\n",
      "I0809 02:13:24.054696 139891397056256 evaluation.py:275] Finished evaluation at 2019-08-09-02:13:24\n",
      "I0809 02:13:24.059770 139891397056256 estimator.py:2039] Saving dict for global step 100: average_loss = 54734900000.0, global_step = 100, label/mean = 204546.2, loss = 6868216300000.0, prediction/mean = 121.8991, rmse = 233954.9\n",
      "I0809 02:13:24.065234 139891397056256 estimator.py:2099] Saving 'checkpoint_path' summary for global step 100: ./housing_trained/model.ckpt-100\n",
      "I0809 02:13:24.128943 139891397056256 estimator.py:368] Loss for final step: 6231394000000.0.\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = './housing_trained'\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir, \n",
    "                       feature_columns = [tf.feature_column.numeric_column('num_rooms'),\n",
    "                                         tf.feature_column.numeric_column('housing_median_age')])\n",
    "  \n",
    "  #Add rmse evaluation metric\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'],tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)}\n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "  \n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = tf.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\", \"housing_median_age\"]],\n",
    "                                              y = traindf[\"median_house_value\"],  # note the scaling\n",
    "                                              num_epochs = None,\n",
    "                                              shuffle = True),\n",
    "                       max_steps = num_train_steps)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = tf.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\", \"housing_median_age\"]],\n",
    "                                              y = evaldf[\"median_house_value\"],  # note the scaling\n",
    "                                              num_epochs = 1,\n",
    "                                              shuffle = False),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       )\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "  \n",
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scale the output\n",
    "Let's scale the target values so that the default parameters are more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0809 02:14:07.342756 139891397056256 estimator.py:1790] Using default config.\n",
      "I0809 02:14:07.344442 139891397056256 estimator.py:209] Using config: {'_experimental_max_worker_delay_secs': None, '_model_dir': './housing_trained', '_task_type': 'worker', '_evaluation_master': '', '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a949ce940>, '_task_id': 0, '_save_checkpoints_steps': None, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_train_distribute': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_max': 5, '_service': None}\n",
      "I0809 02:14:07.346268 139891397056256 estimator.py:209] Using config: {'_experimental_max_worker_delay_secs': None, '_model_dir': './housing_trained', '_task_type': 'worker', '_evaluation_master': '', '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a949ce8d0>, '_task_id': 0, '_save_checkpoints_steps': None, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_train_distribute': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_max': 5, '_service': None}\n",
      "I0809 02:14:07.353399 139891397056256 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0809 02:14:07.354710 139891397056256 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0809 02:14:07.355840 139891397056256 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0809 02:14:07.386984 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:14:07.388697 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:14:07.620784 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:14:07.621839 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:14:07.622840 139891397056256 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0809 02:14:07.749993 139891397056256 monitored_session.py:240] Graph was finalized.\n",
      "I0809 02:14:07.807301 139891397056256 session_manager.py:500] Running local_init_op.\n",
      "I0809 02:14:07.815605 139891397056256 session_manager.py:502] Done running local_init_op.\n",
      "I0809 02:14:08.049822 139891397056256 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./housing_trained/model.ckpt.\n",
      "I0809 02:14:08.278825 139891397056256 basic_session_run_hooks.py:262] loss = 704.3092, step = 1\n",
      "I0809 02:14:08.955218 139891397056256 basic_session_run_hooks.py:606] Saving checkpoints for 100 into ./housing_trained/model.ckpt.\n",
      "I0809 02:14:09.138346 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:14:09.143848 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:14:09.401393 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:14:09.425633 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:14:09.452997 139891397056256 evaluation.py:255] Starting evaluation at 2019-08-09T02:14:09Z\n",
      "I0809 02:14:09.554374 139891397056256 monitored_session.py:240] Graph was finalized.\n",
      "I0809 02:14:09.559636 139891397056256 saver.py:1280] Restoring parameters from ./housing_trained/model.ckpt-100\n",
      "I0809 02:14:09.612098 139891397056256 session_manager.py:500] Running local_init_op.\n",
      "I0809 02:14:09.646851 139891397056256 session_manager.py:502] Done running local_init_op.\n",
      "I0809 02:14:10.107111 139891397056256 evaluation.py:275] Finished evaluation at 2019-08-09-02:14:10\n",
      "I0809 02:14:10.112297 139891397056256 estimator.py:2039] Saving dict for global step 100: average_loss = 1.3886595, global_step = 100, label/mean = 2.0454628, loss = 174.25105, prediction/mean = 2.1540456, rmse = 117841.4\n",
      "I0809 02:14:10.117009 139891397056256 estimator.py:2099] Saving 'checkpoint_path' summary for global step 100: ./housing_trained/model.ckpt-100\n",
      "I0809 02:14:10.193823 139891397056256 estimator.py:368] Loss for final step: 77.53168.\n"
     ]
    }
   ],
   "source": [
    "SCALE = 100000\n",
    "OUTDIR = './housing_trained'\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir, \n",
    "                       feature_columns = [tf.feature_column.numeric_column('num_rooms'),\n",
    "                                         tf.feature_column.numeric_column('housing_median_age')])\n",
    "  \n",
    "  #Add rmse evaluation metric\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'],tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels*SCALE, pred_values*SCALE)}\n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "  \n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = tf.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\", \"housing_median_age\"]],\n",
    "                                              y = traindf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                              num_epochs = None,\n",
    "                                              shuffle = True),\n",
    "                       max_steps = num_train_steps)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = tf.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\", \"housing_median_age\"]],\n",
    "                                              y = evaldf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                              num_epochs = 1,\n",
    "                                              shuffle = False),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       )\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change learning rate and batch size\n",
    "Can you come up with better parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0809 02:15:05.758843 139891397056256 estimator.py:1790] Using default config.\n",
      "I0809 02:15:05.760127 139891397056256 estimator.py:209] Using config: {'_experimental_max_worker_delay_secs': None, '_model_dir': './housing_trained', '_task_type': 'worker', '_evaluation_master': '', '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a4a14b748>, '_task_id': 0, '_save_checkpoints_steps': None, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_train_distribute': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_max': 5, '_service': None}\n",
      "I0809 02:15:05.761508 139891397056256 estimator.py:209] Using config: {'_experimental_max_worker_delay_secs': None, '_model_dir': './housing_trained', '_task_type': 'worker', '_evaluation_master': '', '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a4a14b4e0>, '_task_id': 0, '_save_checkpoints_steps': None, '_eval_distribute': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_train_distribute': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_device_fn': None, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_max': 5, '_service': None}\n",
      "I0809 02:15:05.770017 139891397056256 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0809 02:15:05.771435 139891397056256 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0809 02:15:05.772666 139891397056256 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0809 02:15:05.809064 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:15:05.810410 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:15:06.393370 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:15:06.394685 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:15:06.395800 139891397056256 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0809 02:15:06.523200 139891397056256 monitored_session.py:240] Graph was finalized.\n",
      "I0809 02:15:06.580033 139891397056256 session_manager.py:500] Running local_init_op.\n",
      "I0809 02:15:06.589036 139891397056256 session_manager.py:502] Done running local_init_op.\n",
      "I0809 02:15:06.825119 139891397056256 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./housing_trained/model.ckpt.\n",
      "I0809 02:15:07.080919 139891397056256 basic_session_run_hooks.py:262] loss = 1412.5001, step = 1\n",
      "W0809 02:15:07.320791 139891397056256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 5 vs previous value: 5. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I0809 02:15:08.143399 139891397056256 basic_session_run_hooks.py:606] Saving checkpoints for 100 into ./housing_trained/model.ckpt.\n",
      "I0809 02:15:08.242953 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:15:08.246560 139891397056256 estimator.py:1145] Calling model_fn.\n",
      "I0809 02:15:08.520837 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:15:08.545820 139891397056256 estimator.py:1147] Done calling model_fn.\n",
      "I0809 02:15:08.571095 139891397056256 evaluation.py:255] Starting evaluation at 2019-08-09T02:15:08Z\n",
      "I0809 02:15:08.672317 139891397056256 monitored_session.py:240] Graph was finalized.\n",
      "I0809 02:15:08.675319 139891397056256 saver.py:1280] Restoring parameters from ./housing_trained/model.ckpt-100\n",
      "I0809 02:15:08.726286 139891397056256 session_manager.py:500] Running local_init_op.\n",
      "I0809 02:15:08.761181 139891397056256 session_manager.py:502] Done running local_init_op.\n",
      "I0809 02:15:09.305037 139891397056256 evaluation.py:275] Finished evaluation at 2019-08-09-02:15:09\n",
      "I0809 02:15:09.307070 139891397056256 estimator.py:2039] Saving dict for global step 100: average_loss = 1.5873897, global_step = 100, label/mean = 2.0454628, loss = 199.188, prediction/mean = 1.4554355, rmse = 125991.664\n",
      "I0809 02:15:09.309020 139891397056256 estimator.py:2099] Saving 'checkpoint_path' summary for global step 100: ./housing_trained/model.ckpt-100\n",
      "I0809 02:15:09.381553 139891397056256 estimator.py:368] Loss for final step: 448.0738.\n"
     ]
    }
   ],
   "source": [
    "SCALE = 100000\n",
    "OUTDIR = './housing_trained'\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  myopt = tf.train.FtrlOptimizer(learning_rate = 0.2) # note the learning rate\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir, \n",
    "                       feature_columns = [tf.feature_column.numeric_column('num_rooms'),\n",
    "                                         tf.feature_column.numeric_column('housing_median_age')],\n",
    "                       optimizer = myopt)\n",
    "  \n",
    "  #Add rmse evaluation metric\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'],tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels*SCALE, pred_values*SCALE)}\n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "  \n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = tf.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\", \"housing_median_age\"]],\n",
    "                                              y = traindf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                              num_epochs = None,\n",
    "                                              batch_size = 512, # note the batch size\n",
    "                                              shuffle = True),\n",
    "                       max_steps = num_train_steps)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = tf.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\", \"housing_median_age\"]],\n",
    "                                              y = evaldf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                              num_epochs = 1,\n",
    "                                              shuffle = False),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       )\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QU5sLyYTqzqL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Is there a standard method for tuning the model?\n",
    "\n",
    "This is a commonly asked question. The short answer is that the effects of different hyperparameters is data dependent.  So there are no hard and fast rules; you'll need to run tests on your data.\n",
    "\n",
    "Here are a few rules of thumb that may help guide you:\n",
    "\n",
    " * Training error should steadily decrease, steeply at first, and should eventually plateau as training converges.\n",
    " * If the training has not converged, try running it for longer.\n",
    " * If the training error decreases too slowly, increasing the learning rate may help it decrease faster.\n",
    "   * But sometimes the exact opposite may happen if the learning rate is too high.\n",
    " * If the training error varies wildly, try decreasing the learning rate.\n",
    "   * Lower learning rate plus larger number of steps or larger batch size is often a good combination.\n",
    " * Very small batch sizes can also cause instability.  First try larger values like 100 or 1000, and decrease until you see degradation.\n",
    "\n",
    "Again, never go strictly by these rules of thumb, because the effects are data dependent.  Always experiment and verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpV-uF_cBCBU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3: Try adding more features\n",
    "\n",
    "See if you can do any better by adding more features.\n",
    "\n",
    "Don't take more than 5 minutes on this portion."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
