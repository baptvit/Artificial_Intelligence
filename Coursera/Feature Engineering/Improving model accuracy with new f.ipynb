{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Trying out features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Learning Objectives:**\n",
    "  * Improve the accuracy of a model by adding new features with the appropriate representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The data is based on 1990 census data from California. This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Set Up\n",
    "In this first cell, we'll load the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Next, we'll load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Examine and split the data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it.\n",
    "\n",
    "We'll print out a quick summary of a few useful statistics on each column.\n",
    "\n",
    "This will include things like mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0     -114.3      34.2                15.0       5612.0          1283.0   \n",
       "1     -114.5      34.4                19.0       7650.0          1901.0   \n",
       "2     -114.6      33.7                17.0        720.0           174.0   \n",
       "3     -114.6      33.6                14.0       1501.0           337.0   \n",
       "4     -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0            1.5             66900.0  \n",
       "1      1129.0       463.0            1.8             80100.0  \n",
       "2       333.0       117.0            1.7             85700.0  \n",
       "3       515.0       226.0            3.2             73400.0  \n",
       "4       624.0       262.0            1.9             65500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9            207300.9  \n",
       "std        1147.9       384.5            1.9            115983.8  \n",
       "min           3.0         1.0            0.5             14999.0  \n",
       "25%         790.0       282.0            2.6            119400.0  \n",
       "50%        1167.0       409.0            3.5            180400.0  \n",
       "75%        1721.0       605.2            4.8            265000.0  \n",
       "max       35682.0      6082.0           15.0            500001.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, split the data into two parts -- training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16993</th>\n",
       "      <td>-124.2</td>\n",
       "      <td>40.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>106700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16994</th>\n",
       "      <td>-124.2</td>\n",
       "      <td>40.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>76100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>40.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>111400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>41.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>103600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>41.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "16993     -124.2      40.5                52.0       2694.0           453.0   \n",
       "16994     -124.2      40.3                32.0       1430.0           419.0   \n",
       "16995     -124.3      40.6                52.0       2217.0           394.0   \n",
       "16997     -124.3      41.8                17.0       2677.0           531.0   \n",
       "16998     -124.3      41.8                19.0       2672.0           552.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "16993      1152.0       435.0            3.1            106700.0  \n",
       "16994       434.0       187.0            1.9             76100.0  \n",
       "16995       907.0       369.0            2.4            111400.0  \n",
       "16997      1244.0       456.0            3.0            103600.0  \n",
       "16998      1298.0       478.0            2.0             85800.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed=1) #makes result reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]\n",
    "\n",
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "In this exercise, we'll be trying to predict **median_house_value** It will be our label (sometimes also called a target).\n",
    "\n",
    "We'll modify the feature_cols and input function to represent the features you want to use.\n",
    "\n",
    "We divide **total_rooms** by **households** to get **avg_rooms_per_house** which we expect to positively correlate with **median_house_value**. \n",
    "\n",
    "We also divide **population** by **total_rooms** to get **avg_persons_per_room** which we expect to negatively correlate with **median_house_value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_more_features(df):\n",
    "  df['avg_rooms_per_house'] = df['total_rooms'] / df['households'] #expect positive correlation\n",
    "  df['avg_persons_per_room'] = df['population'] / df['total_rooms'] #expect negative correlation\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create pandas input function\n",
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = add_more_features(df),\n",
    "    y = df['median_house_value'] / 100000, # will talk about why later in the course\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define your feature columns\n",
    "def create_feature_cols():\n",
    "  return [\n",
    "    tf.feature_column.numeric_column('housing_median_age'),\n",
    "    tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), boundaries = np.arange(32.0, 42, 1).tolist()),\n",
    "    tf.feature_column.numeric_column('avg_rooms_per_house'),\n",
    "    tf.feature_column.numeric_column('avg_persons_per_room'),\n",
    "    tf.feature_column.numeric_column('median_income')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(model_dir = output_dir, feature_columns = create_feature_cols())\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Launch tensorboard\n",
    "OUTDIR = './trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0804 14:01:56.390665 140141194147584 estimator.py:1790] Using default config.\n",
      "I0804 14:01:56.392723 140141194147584 estimator.py:209] Using config: {'_model_dir': './trained_model', '_eval_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_save_summary_steps': 100, '_device_fn': None, '_task_id': 0, '_evaluation_master': '', '_service': None, '_global_id_in_cluster': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_experimental_distribute': None, '_protocol': None, '_experimental_max_worker_delay_secs': None, '_master': '', '_train_distribute': None, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_tf_random_seed': None, '_is_chief': True, '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f74c71cc198>, '_keep_checkpoint_max': 5}\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "I0804 14:01:56.414064 140141194147584 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0804 14:01:56.415706 140141194147584 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0804 14:01:56.417378 140141194147584 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "W0804 14:01:56.441631 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0804 14:01:56.469420 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0804 14:01:56.472501 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0804 14:01:56.485493 140141194147584 estimator.py:1145] Calling model_fn.\n",
      "W0804 14:01:56.865662 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0804 14:01:56.961620 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "I0804 14:01:57.540103 140141194147584 estimator.py:1147] Done calling model_fn.\n",
      "I0804 14:01:57.542098 140141194147584 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0804 14:01:57.831560 140141194147584 monitored_session.py:240] Graph was finalized.\n",
      "I0804 14:01:57.941203 140141194147584 session_manager.py:500] Running local_init_op.\n",
      "I0804 14:01:57.955633 140141194147584 session_manager.py:502] Done running local_init_op.\n",
      "W0804 14:01:58.000008 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0804 14:01:58.406935 140141194147584 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "I0804 14:01:58.944465 140141194147584 basic_session_run_hooks.py:262] loss = 712.93066, step = 1\n",
      "W0804 14:01:59.283021 140141194147584 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 15 vs previous value: 15. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0804 14:01:59.445719 140141194147584 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 40 vs previous value: 40. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0804 14:01:59.735383 140141194147584 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 87 vs previous value: 87. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0804 14:01:59.757195 140141194147584 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 90 vs previous value: 90. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I0804 14:01:59.823066 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 113.775\n",
      "I0804 14:01:59.827623 140141194147584 basic_session_run_hooks.py:260] loss = 148.35121, step = 101 (0.883 sec)\n",
      "W0804 14:02:00.007671 140141194147584 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 135 vs previous value: 135. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I0804 14:02:00.338626 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 193.908\n",
      "I0804 14:02:00.343056 140141194147584 basic_session_run_hooks.py:260] loss = 54.219425, step = 201 (0.515 sec)\n",
      "I0804 14:02:00.966893 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 159.186\n",
      "I0804 14:02:00.976545 140141194147584 basic_session_run_hooks.py:260] loss = 66.14032, step = 301 (0.633 sec)\n",
      "I0804 14:02:01.901460 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 106.999\n",
      "I0804 14:02:01.913472 140141194147584 basic_session_run_hooks.py:260] loss = 59.00797, step = 401 (0.937 sec)\n",
      "I0804 14:02:02.798664 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 111.459\n",
      "I0804 14:02:02.801148 140141194147584 basic_session_run_hooks.py:260] loss = 69.19346, step = 501 (0.888 sec)\n",
      "I0804 14:02:03.781845 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 101.712\n",
      "I0804 14:02:03.788090 140141194147584 basic_session_run_hooks.py:260] loss = 77.02089, step = 601 (0.987 sec)\n",
      "I0804 14:02:04.819162 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 96.4022\n",
      "I0804 14:02:04.821468 140141194147584 basic_session_run_hooks.py:260] loss = 87.35302, step = 701 (1.033 sec)\n",
      "I0804 14:02:05.875045 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 94.7079\n",
      "I0804 14:02:05.882288 140141194147584 basic_session_run_hooks.py:260] loss = 59.751175, step = 801 (1.061 sec)\n",
      "I0804 14:02:06.854646 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 102.081\n",
      "I0804 14:02:06.857094 140141194147584 basic_session_run_hooks.py:260] loss = 73.36575, step = 901 (0.975 sec)\n",
      "I0804 14:02:07.826665 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 102.879\n",
      "I0804 14:02:07.829598 140141194147584 basic_session_run_hooks.py:260] loss = 92.04374, step = 1001 (0.973 sec)\n",
      "I0804 14:02:08.897169 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 93.4133\n",
      "I0804 14:02:08.900122 140141194147584 basic_session_run_hooks.py:260] loss = 68.342255, step = 1101 (1.071 sec)\n",
      "I0804 14:02:09.984240 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 91.9901\n",
      "I0804 14:02:09.987108 140141194147584 basic_session_run_hooks.py:260] loss = 51.065033, step = 1201 (1.087 sec)\n",
      "I0804 14:02:11.012726 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 97.2305\n",
      "I0804 14:02:11.015596 140141194147584 basic_session_run_hooks.py:260] loss = 66.5244, step = 1301 (1.029 sec)\n",
      "I0804 14:02:12.123533 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 90.022\n",
      "I0804 14:02:12.126117 140141194147584 basic_session_run_hooks.py:260] loss = 47.410088, step = 1401 (1.111 sec)\n",
      "I0804 14:02:13.152720 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 97.1691\n",
      "I0804 14:02:13.159497 140141194147584 basic_session_run_hooks.py:260] loss = 69.750946, step = 1501 (1.033 sec)\n",
      "I0804 14:02:14.170704 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 98.2271\n",
      "I0804 14:02:14.175626 140141194147584 basic_session_run_hooks.py:260] loss = 72.37886, step = 1601 (1.016 sec)\n",
      "I0804 14:02:15.204551 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 96.7357\n",
      "I0804 14:02:15.212594 140141194147584 basic_session_run_hooks.py:260] loss = 108.85216, step = 1701 (1.037 sec)\n",
      "I0804 14:02:16.152711 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 105.46\n",
      "I0804 14:02:16.158454 140141194147584 basic_session_run_hooks.py:260] loss = 129.34293, step = 1801 (0.946 sec)\n",
      "I0804 14:02:17.299921 140141194147584 basic_session_run_hooks.py:692] global_step/sec: 87.1697\n",
      "I0804 14:02:17.307302 140141194147584 basic_session_run_hooks.py:260] loss = 78.08801, step = 1901 (1.149 sec)\n",
      "I0804 14:02:18.345853 140141194147584 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into ./trained_model/model.ckpt.\n",
      "I0804 14:02:18.577462 140141194147584 estimator.py:1145] Calling model_fn.\n",
      "I0804 14:02:19.309787 140141194147584 estimator.py:1147] Done calling model_fn.\n",
      "I0804 14:02:19.335813 140141194147584 evaluation.py:255] Starting evaluation at 2019-08-04T14:02:19Z\n",
      "I0804 14:02:19.460960 140141194147584 monitored_session.py:240] Graph was finalized.\n",
      "W0804 14:02:19.463317 140141194147584 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0804 14:02:19.465564 140141194147584 saver.py:1280] Restoring parameters from ./trained_model/model.ckpt-2000\n",
      "I0804 14:02:19.537415 140141194147584 session_manager.py:500] Running local_init_op.\n",
      "I0804 14:02:19.571606 140141194147584 session_manager.py:502] Done running local_init_op.\n",
      "I0804 14:02:20.434163 140141194147584 evaluation.py:275] Finished evaluation at 2019-08-04-14:02:20\n",
      "I0804 14:02:20.435874 140141194147584 estimator.py:2039] Saving dict for global step 2000: average_loss = 0.60856986, global_step = 2000, label/mean = 2.0454628, loss = 76.36425, prediction/mean = 1.9197\n",
      "I0804 14:02:20.539789 140141194147584 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2000: ./trained_model/model.ckpt-2000\n",
      "I0804 14:02:20.622323 140141194147584 estimator.py:368] Loss for final step: 70.82942.\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate(OUTDIR, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
